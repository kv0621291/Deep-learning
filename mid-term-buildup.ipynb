{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# CSV 파일 로드\n",
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "# 데이터 정보 확인\n",
    "data.info()\n",
    "\n",
    "# 기본 통계량 확인\n",
    "data.describe()\n",
    "\n",
    "# 결측치 확인\n",
    "data.isnull().sum()\n",
    "\n",
    "# 결측치 제거, 확인\n",
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# pairplot를 사용해 각 상관관계 살펴보기\n",
    "\n",
    "sns.pairplot(df,\n",
    "             vars=['mean radius', 'mean texture', 'mean perimeter', 'mean area'],\n",
    "            hue ='label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 산점도 확인\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.scatter(df['mean radius'], df['mean texture'])\n",
    "plt.xlabel('Mean Radius')\n",
    "plt.ylabel('Mean Texture')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 컬렴명 확인\n",
    "df.columns\n",
    "\n",
    "# 레이블 갯수 확인 (그래프)\n",
    "sns.countplot(data = df, x=\"label\")\n",
    "plt.xlabel(\"Cancer or Not\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Label\")\n",
    "\n",
    "# 레이블 갯수 확인 (숫자)\n",
    "df['label'].value_counts()\n",
    "\n",
    "# 레이블별 갯수 확인\n",
    "label_counts = df['activity'].value_counts()\n",
    "\n",
    "# 바 그래프 그리기\n",
    "label_counts.plot(kind='bar')\n",
    "\n",
    "# 그래프 제목 및 라벨 설정\n",
    "plt.title('Label Count')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 원 핫 인코딩(문자열의 경우)후 train/test 분할\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train,y_test = train_test_split(X_encoded,Y,test_size=0.2,random_state=0) \n",
    "\n",
    "# random_state는 0일 때 매번 같은 세트, 임의의 정수는 무작위 시드로 분할함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# train/test 분할\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop('label_column', axis=1)\n",
    "y = data['label_column']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# split_sequence 정의\n",
    "\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps\n",
    "        # 시퀀스 끝을 넘어가면 중단\n",
    "        if end_ix > len(sequence) - 1:\n",
    "            break\n",
    "        # 입력 시퀀스와 출력 시퀀스 분리\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 데이터 분할\n",
    "\n",
    "X, y = split_sequence(sequence, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 모델\n",
    "\n",
    "from keras.layers import LSTM\n",
    "\n",
    "def create_cnn_lstm_model(input_shape, output_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.2),\n",
    "        Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        LSTM(50, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(output_shape, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 층 추가한 모델\n",
    "# Dense 층 조절하는게 제일 좋을 듯\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, MaxPooling1D, UpSampling1D, Dense, Flatten, Input, LSTM, Dropout\n",
    "\n",
    "def create_cnn_lstm_model(input_shape, output_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv1D(128, kernel_size=3, activation='relu'),  # 더 깊은 Conv1D 층 추가\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Conv1D(256, kernel_size=3, activation='relu'),  # 추가된 또 다른 Conv1D 층\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        LSTM(100, activation='relu'),  # LSTM의 유닛 수 증가\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(128, activation='relu'),  # 추가된 Dense 층\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(64, activation='relu'),  # 추가된 Dense 층\n",
    "        Dense(output_shape, activation='sigmoid')  # 출력층\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# 오토 인코더\n",
    "\n",
    "def create_autoencoder(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # 인코더\n",
    "    x = Conv1D(32, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    x = Conv1D(64, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling1D(pool_size=2)(x)  # 이 레이어가 저차원 잠재 공간 (compressed representation)\n",
    "\n",
    "    # 디코더\n",
    "    x = Conv1D(64, kernel_size=3, activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling1D(size=2)(x)\n",
    "    \n",
    "    x = Conv1D(32, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    decoded = UpSampling1D(size=2)(x)\n",
    "    \n",
    "    # 입력과 같은 크기로 복원\n",
    "    decoded = Conv1D(input_shape[1], kernel_size=3, activation='sigmoid', padding='same')(decoded)\n",
    "\n",
    "    autoencoder = Model(input_layer, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "\n",
    "# 오토인코더 + CNN + LSTM\n",
    "\n",
    "def create_cnn_lstm_with_autoencoder(input_shape, output_shape):\n",
    "    # 오토인코더 생성 및 학습\n",
    "    autoencoder = create_autoencoder(input_shape)\n",
    "    autoencoder.summary()\n",
    "    \n",
    "    # 오토인코더의 인코더 부분을 가져옴 (즉, 특징을 추출하는 부분)\n",
    "    encoder = Model(inputs=autoencoder.input, outputs=autoencoder.layers[4].output)  # encoded layer 선택\n",
    "    \n",
    "    # CNN-LSTM 모델 구성\n",
    "    model_input = Input(shape=input_shape)\n",
    "    encoded_features = encoder(model_input)  # 오토인코더의 인코더로부터 추출된 특징을 사용\n",
    "    \n",
    "    # CNN + LSTM 층 추가\n",
    "    x = Conv1D(64, kernel_size=3, activation='relu')(encoded_features)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = LSTM(50, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    output_layer = Dense(output_shape, activation='sigmoid')(x)\n",
    "    \n",
    "    cnn_lstm_model = Model(model_input, output_layer)\n",
    "    cnn_lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return autoencoder, cnn_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "\n",
    "input_shape = (100, 1)  # n_steps=100, n_features=1\n",
    "output_shape = 1  # 이진 분류이므로 1\n",
    "\n",
    "# 모델 생성\n",
    "model = create_cnn_lstm_model(input_shape, output_shape)\n",
    "\n",
    "# 모델 요약 정보 출력\n",
    "model.summary()\n",
    "\n",
    "# 데이터 준비 후 모델 학습\n",
    "# model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 성능 평가\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
