{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f63fbb8a-9965-48e0-ab3e-17ac030371ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8af15d0b-5d90-4b1f-a830-b89da2569e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>F</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>M</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>M</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>F</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>M</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "id                                                                 \n",
       "0      M   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1      M   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2      F   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3      M   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4      I   0.330     0.255   0.080        0.2050          0.0895   \n",
       "...   ..     ...       ...     ...           ...             ...   \n",
       "4172   F   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173   M   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174   M   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175   F   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176   M   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera_weight  Shell_weight  Rings  \n",
       "id                                         \n",
       "0             0.1010        0.1500     15  \n",
       "1             0.0485        0.0700      7  \n",
       "2             0.1415        0.2100      9  \n",
       "3             0.1140        0.1550     10  \n",
       "4             0.0395        0.0550      7  \n",
       "...              ...           ...    ...  \n",
       "4172          0.2390        0.2490     11  \n",
       "4173          0.2145        0.2605     10  \n",
       "4174          0.2875        0.3080      9  \n",
       "4175          0.2610        0.2960     10  \n",
       "4176          0.3765        0.4950     12  \n",
       "\n",
       "[4177 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "df = pd.read_csv(\"abalone.csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c71c9419-e282-41cb-a6b8-e59f2cb56fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sex', 'Length', 'Diameter', 'Height', 'Whole_weight', 'Shucked_weight',\n",
       "       'Viscera_weight', 'Shell_weight', 'Rings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2c40000-07de-4ff5-bd02-bf11d75ad2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex               0\n",
       "Length            0\n",
       "Diameter          0\n",
       "Height            0\n",
       "Whole_weight      0\n",
       "Shucked_weight    0\n",
       "Viscera_weight    0\n",
       "Shell_weight      0\n",
       "Rings             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fea9a583-9809-41f9-85d0-501a8b4d70fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex               0\n",
       "Length            0\n",
       "Diameter          0\n",
       "Height            0\n",
       "Whole_weight      0\n",
       "Shucked_weight    0\n",
       "Viscera_weight    0\n",
       "Shell_weight      0\n",
       "Rings             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "319bd88e-53d1-45a7-baa0-a57ce24cd420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "id                                                               \n",
       "0    M   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1    M   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2    F   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3    M   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4    I   0.330     0.255   0.080        0.2050          0.0895   \n",
       "\n",
       "    Viscera_weight  Shell_weight  \n",
       "id                                \n",
       "0           0.1010         0.150  \n",
       "1           0.0485         0.070  \n",
       "2           0.1415         0.210  \n",
       "3           0.1140         0.155  \n",
       "4           0.0395         0.055  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Rings', axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6644f4a4-ce61-4b4d-8f51-bf9a68fbfd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rings\n",
       "1       1\n",
       "2       1\n",
       "3      15\n",
       "4      57\n",
       "5     115\n",
       "6     259\n",
       "7     391\n",
       "8     568\n",
       "9     689\n",
       "10    634\n",
       "11    487\n",
       "12    267\n",
       "13    203\n",
       "14    126\n",
       "15    103\n",
       "16     67\n",
       "17     58\n",
       "18     42\n",
       "19     32\n",
       "20     26\n",
       "21     14\n",
       "22      6\n",
       "23      9\n",
       "24      2\n",
       "25      1\n",
       "26      1\n",
       "27      2\n",
       "29      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df['Rings']\n",
    "y.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16292589-8090-40b6-8bd9-848337835e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0    15\n",
       "1     7\n",
       "2     9\n",
       "3    10\n",
       "4     7\n",
       "Name: Rings, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4c7db05-1d4b-4ac6-a99f-7058d7df20b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_encoded = encoder.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ce468f1-38e4-4560-a371-c0d49127bea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>F</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>M</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>M</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>F</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>M</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "id                                                                 \n",
       "0      M   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1      M   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2      F   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3      M   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4      I   0.330     0.255   0.080        0.2050          0.0895   \n",
       "...   ..     ...       ...     ...           ...             ...   \n",
       "4172   F   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173   M   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174   M   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175   F   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176   M   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera_weight  Shell_weight  \n",
       "id                                  \n",
       "0             0.1010        0.1500  \n",
       "1             0.0485        0.0700  \n",
       "2             0.1415        0.2100  \n",
       "3             0.1140        0.1550  \n",
       "4             0.0395        0.0550  \n",
       "...              ...           ...  \n",
       "4172          0.2390        0.2490  \n",
       "4173          0.2145        0.2605  \n",
       "4174          0.2875        0.3080  \n",
       "4175          0.2610        0.2960  \n",
       "4176          0.3765        0.4950  \n",
       "\n",
       "[4177 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7894cd4a-25d3-4a3b-a91b-af104f65ba78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['M', 0.455, 0.365, ..., 0.2245, 0.101, 0.15],\n",
       "       ['M', 0.35, 0.265, ..., 0.0995, 0.0485, 0.07],\n",
       "       ['F', 0.53, 0.42, ..., 0.2565, 0.1415, 0.21],\n",
       "       ...,\n",
       "       ['M', 0.6, 0.475, ..., 0.5255, 0.2875, 0.308],\n",
       "       ['F', 0.625, 0.485, ..., 0.531, 0.261, 0.296],\n",
       "       ['M', 0.71, 0.555, ..., 0.9455, 0.3765, 0.495]], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbf30e51-2abe-4382-af85-020b7569fe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eed20803-aa5e-48a3-bc39-21af2404cfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
      "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "\n",
      "   Shell_weight  Sex_F  Sex_I  Sex_M  \n",
      "0         0.150    0.0    0.0    1.0  \n",
      "1         0.070    0.0    0.0    1.0  \n",
      "2         0.210    1.0    0.0    0.0  \n",
      "3         0.155    0.0    0.0    1.0  \n",
      "4         0.055    0.0    1.0    0.0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('abalone.csv')\n",
    "\n",
    "column_to_encode = 'Sex'\n",
    "X = df[[column_to_encode]]\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out([column_to_encode]))\n",
    "\n",
    "df = df.drop(columns=[column_to_encode, 'Rings', 'id'])\n",
    "df = pd.concat([df, encoded_df], axis=1)\n",
    "X = df\n",
    "\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46e6b605-addc-4b5c-bfc9-e33adf424eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
       "0      0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1      0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2      0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3      0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4      0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "...      ...       ...     ...           ...             ...             ...   \n",
       "4172   0.565     0.450   0.165        0.8870          0.3700          0.2390   \n",
       "4173   0.590     0.440   0.135        0.9660          0.4390          0.2145   \n",
       "4174   0.600     0.475   0.205        1.1760          0.5255          0.2875   \n",
       "4175   0.625     0.485   0.150        1.0945          0.5310          0.2610   \n",
       "4176   0.710     0.555   0.195        1.9485          0.9455          0.3765   \n",
       "\n",
       "      Shell_weight  Sex_F  Sex_I  Sex_M  \n",
       "0           0.1500    0.0    0.0    1.0  \n",
       "1           0.0700    0.0    0.0    1.0  \n",
       "2           0.2100    1.0    0.0    0.0  \n",
       "3           0.1550    0.0    0.0    1.0  \n",
       "4           0.0550    0.0    1.0    0.0  \n",
       "...            ...    ...    ...    ...  \n",
       "4172        0.2490    1.0    0.0    0.0  \n",
       "4173        0.2605    0.0    0.0    1.0  \n",
       "4174        0.3080    0.0    0.0    1.0  \n",
       "4175        0.2960    1.0    0.0    0.0  \n",
       "4176        0.4950    0.0    0.0    1.0  \n",
       "\n",
       "[4177 rows x 10 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c89a47f-cf58-405f-be06-183707ae450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(y).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fac9d675-7ee7-412c-bbe7-4b293af78345",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "76634db3-b57a-4b5d-915f-d696f7349e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.455, 0.365, 0.095, ..., 0.   , 0.   , 1.   ],\n",
       "       [0.35 , 0.265, 0.09 , ..., 0.   , 0.   , 1.   ],\n",
       "       [0.53 , 0.42 , 0.135, ..., 1.   , 0.   , 0.   ],\n",
       "       ...,\n",
       "       [0.6  , 0.475, 0.205, ..., 0.   , 0.   , 1.   ],\n",
       "       [0.625, 0.485, 0.15 , ..., 1.   , 0.   , 0.   ],\n",
       "       [0.71 , 0.555, 0.195, ..., 0.   , 0.   , 1.   ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df171fdd-e440-49c2-a7b7-94bc55448462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e0401aa-6f8f-4345-9792-862e3199f672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3341, 10), (3341, 28), (836, 10), (836, 28))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c8a75eb-d69c-49df-be72-907d061103eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_cnn_model(input_shape, output_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.2),\n",
    "        Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(output_shape, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "659a8cef-98c3-41d3-87f2-21d4a3d98a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.0421 - loss: 0.4464 - val_accuracy: 0.1782 - val_loss: 0.1298\n",
      "Epoch 2/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.1772 - loss: 0.1248 - val_accuracy: 0.1651 - val_loss: 0.1213\n",
      "Epoch 3/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.1901 - loss: 0.1198 - val_accuracy: 0.2153 - val_loss: 0.1177\n",
      "Epoch 4/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.2261 - loss: 0.1152 - val_accuracy: 0.2368 - val_loss: 0.1154\n",
      "Epoch 5/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.2348 - loss: 0.1126 - val_accuracy: 0.2285 - val_loss: 0.1141\n",
      "Epoch 6/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.2389 - loss: 0.1119 - val_accuracy: 0.2177 - val_loss: 0.1134\n",
      "Epoch 7/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.2187 - loss: 0.1119 - val_accuracy: 0.2428 - val_loss: 0.1117\n",
      "Epoch 8/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.2380 - loss: 0.1105 - val_accuracy: 0.2488 - val_loss: 0.1115\n",
      "Epoch 9/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.2043 - loss: 0.1112 - val_accuracy: 0.2356 - val_loss: 0.1118\n",
      "Epoch 10/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.2388 - loss: 0.1098 - val_accuracy: 0.2344 - val_loss: 0.1118\n",
      "Epoch 11/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.2407 - loss: 0.1094 - val_accuracy: 0.2368 - val_loss: 0.1107\n",
      "Epoch 12/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.2397 - loss: 0.1092 - val_accuracy: 0.2440 - val_loss: 0.1105\n",
      "Epoch 13/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.2425 - loss: 0.1098 - val_accuracy: 0.2464 - val_loss: 0.1111\n",
      "Epoch 14/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.2426 - loss: 0.1080 - val_accuracy: 0.2476 - val_loss: 0.1105\n",
      "Epoch 15/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.2512 - loss: 0.1086 - val_accuracy: 0.2727 - val_loss: 0.1096\n",
      "Epoch 16/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.2505 - loss: 0.1083 - val_accuracy: 0.2679 - val_loss: 0.1090\n",
      "Epoch 17/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.2543 - loss: 0.1077 - val_accuracy: 0.2476 - val_loss: 0.1092\n",
      "Epoch 18/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.2540 - loss: 0.1083 - val_accuracy: 0.2416 - val_loss: 0.1104\n",
      "Epoch 19/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.2512 - loss: 0.1085 - val_accuracy: 0.2644 - val_loss: 0.1083\n",
      "Epoch 20/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.2420 - loss: 0.1086 - val_accuracy: 0.2225 - val_loss: 0.1091\n",
      "Epoch 21/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.2469 - loss: 0.1080 - val_accuracy: 0.2500 - val_loss: 0.1086\n",
      "Epoch 22/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.2570 - loss: 0.1073 - val_accuracy: 0.2667 - val_loss: 0.1081\n",
      "Epoch 23/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.2336 - loss: 0.1065 - val_accuracy: 0.2739 - val_loss: 0.1078\n",
      "Epoch 24/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.2567 - loss: 0.1062 - val_accuracy: 0.2703 - val_loss: 0.1070\n",
      "Epoch 25/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.2523 - loss: 0.1065 - val_accuracy: 0.2739 - val_loss: 0.1065\n",
      "Epoch 26/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.2621 - loss: 0.1054 - val_accuracy: 0.2608 - val_loss: 0.1062\n",
      "Epoch 27/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.2552 - loss: 0.1047 - val_accuracy: 0.2632 - val_loss: 0.1062\n",
      "Epoch 28/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.2548 - loss: 0.1048 - val_accuracy: 0.2667 - val_loss: 0.1062\n",
      "Epoch 29/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.2610 - loss: 0.1056 - val_accuracy: 0.2703 - val_loss: 0.1057\n",
      "Epoch 30/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.2538 - loss: 0.1042 - val_accuracy: 0.2775 - val_loss: 0.1049\n",
      "Epoch 31/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.2515 - loss: 0.1038 - val_accuracy: 0.2632 - val_loss: 0.1049\n",
      "Epoch 32/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.2656 - loss: 0.1039 - val_accuracy: 0.2536 - val_loss: 0.1054\n",
      "Epoch 33/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.2748 - loss: 0.1034 - val_accuracy: 0.2871 - val_loss: 0.1043\n",
      "Epoch 34/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.2505 - loss: 0.1047 - val_accuracy: 0.2679 - val_loss: 0.1053\n",
      "Epoch 35/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.2704 - loss: 0.1030 - val_accuracy: 0.2656 - val_loss: 0.1043\n",
      "Epoch 36/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.2720 - loss: 0.1028 - val_accuracy: 0.2739 - val_loss: 0.1053\n",
      "Epoch 37/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.2772 - loss: 0.1027 - val_accuracy: 0.2608 - val_loss: 0.1048\n",
      "Epoch 38/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.2666 - loss: 0.1023 - val_accuracy: 0.2703 - val_loss: 0.1055\n",
      "Epoch 39/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.2631 - loss: 0.1031 - val_accuracy: 0.2811 - val_loss: 0.1032\n",
      "Epoch 40/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.2716 - loss: 0.1027 - val_accuracy: 0.2715 - val_loss: 0.1041\n",
      "Epoch 41/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.2813 - loss: 0.1020 - val_accuracy: 0.2620 - val_loss: 0.1038\n",
      "Epoch 42/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.2794 - loss: 0.1034 - val_accuracy: 0.2727 - val_loss: 0.1035\n",
      "Epoch 43/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.2848 - loss: 0.1015 - val_accuracy: 0.2691 - val_loss: 0.1038\n",
      "Epoch 44/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.2739 - loss: 0.1017 - val_accuracy: 0.2787 - val_loss: 0.1032\n",
      "Epoch 45/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.2874 - loss: 0.1019 - val_accuracy: 0.2775 - val_loss: 0.1032\n",
      "Epoch 46/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.2832 - loss: 0.1019 - val_accuracy: 0.2691 - val_loss: 0.1032\n",
      "Epoch 47/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.2794 - loss: 0.1014 - val_accuracy: 0.2823 - val_loss: 0.1034\n",
      "Epoch 48/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.2715 - loss: 0.1015 - val_accuracy: 0.2871 - val_loss: 0.1031\n",
      "Epoch 49/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.2619 - loss: 0.1016 - val_accuracy: 0.2727 - val_loss: 0.1027\n",
      "Epoch 50/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.2674 - loss: 0.1014 - val_accuracy: 0.2691 - val_loss: 0.1039\n",
      "Epoch 51/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.2858 - loss: 0.1015 - val_accuracy: 0.2751 - val_loss: 0.1037\n",
      "Epoch 52/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.2798 - loss: 0.1010 - val_accuracy: 0.2787 - val_loss: 0.1029\n",
      "Epoch 53/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.2802 - loss: 0.1014 - val_accuracy: 0.2644 - val_loss: 0.1031\n",
      "Epoch 54/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.2589 - loss: 0.1037 - val_accuracy: 0.2727 - val_loss: 0.1027\n",
      "Epoch 55/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.2715 - loss: 0.1013 - val_accuracy: 0.2703 - val_loss: 0.1026\n",
      "Epoch 56/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.2890 - loss: 0.1018 - val_accuracy: 0.2620 - val_loss: 0.1031\n",
      "Epoch 57/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.2729 - loss: 0.1027 - val_accuracy: 0.2763 - val_loss: 0.1026\n",
      "Epoch 58/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.2837 - loss: 0.0998 - val_accuracy: 0.2727 - val_loss: 0.1028\n",
      "Epoch 59/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.2715 - loss: 0.1007 - val_accuracy: 0.2739 - val_loss: 0.1025\n",
      "Epoch 60/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.2894 - loss: 0.1003 - val_accuracy: 0.2751 - val_loss: 0.1025\n",
      "Epoch 61/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.2983 - loss: 0.1011 - val_accuracy: 0.2763 - val_loss: 0.1026\n",
      "Epoch 62/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.2675 - loss: 0.1012 - val_accuracy: 0.2691 - val_loss: 0.1027\n",
      "Epoch 63/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.2845 - loss: 0.1009 - val_accuracy: 0.2847 - val_loss: 0.1025\n",
      "Epoch 64/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.2757 - loss: 0.1002 - val_accuracy: 0.2715 - val_loss: 0.1020\n",
      "Epoch 65/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.2881 - loss: 0.1004 - val_accuracy: 0.2667 - val_loss: 0.1022\n",
      "Epoch 66/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.2889 - loss: 0.1014 - val_accuracy: 0.2667 - val_loss: 0.1024\n",
      "Epoch 67/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.2597 - loss: 0.1015 - val_accuracy: 0.2835 - val_loss: 0.1021\n",
      "Epoch 68/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.2809 - loss: 0.1014 - val_accuracy: 0.2644 - val_loss: 0.1027\n",
      "Epoch 69/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.2889 - loss: 0.1016 - val_accuracy: 0.2727 - val_loss: 0.1022\n",
      "Epoch 70/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.2887 - loss: 0.0998 - val_accuracy: 0.2823 - val_loss: 0.1019\n",
      "Epoch 71/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.2672 - loss: 0.1008 - val_accuracy: 0.2787 - val_loss: 0.1024\n",
      "Epoch 72/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.2814 - loss: 0.1002 - val_accuracy: 0.2811 - val_loss: 0.1023\n",
      "Epoch 73/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.2833 - loss: 0.1001 - val_accuracy: 0.2679 - val_loss: 0.1031\n",
      "Epoch 74/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.2774 - loss: 0.1001 - val_accuracy: 0.2847 - val_loss: 0.1018\n",
      "Epoch 75/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.2766 - loss: 0.1000 - val_accuracy: 0.2931 - val_loss: 0.1022\n",
      "Epoch 76/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.2669 - loss: 0.1007 - val_accuracy: 0.2644 - val_loss: 0.1023\n",
      "Epoch 77/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.2710 - loss: 0.1010 - val_accuracy: 0.2811 - val_loss: 0.1017\n",
      "Epoch 78/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.2910 - loss: 0.1010 - val_accuracy: 0.2703 - val_loss: 0.1019\n",
      "Epoch 79/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.2603 - loss: 0.1012 - val_accuracy: 0.2883 - val_loss: 0.1021\n",
      "Epoch 80/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.2652 - loss: 0.1012 - val_accuracy: 0.2715 - val_loss: 0.1027\n",
      "Epoch 81/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.2910 - loss: 0.1005 - val_accuracy: 0.2632 - val_loss: 0.1024\n",
      "Epoch 82/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.2829 - loss: 0.0995 - val_accuracy: 0.2727 - val_loss: 0.1018\n",
      "Epoch 83/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.2859 - loss: 0.0996 - val_accuracy: 0.2751 - val_loss: 0.1023\n",
      "Epoch 84/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.2962 - loss: 0.0994 - val_accuracy: 0.2775 - val_loss: 0.1016\n",
      "Epoch 85/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.2855 - loss: 0.0992 - val_accuracy: 0.2859 - val_loss: 0.1019\n",
      "Epoch 86/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.2871 - loss: 0.1006 - val_accuracy: 0.2823 - val_loss: 0.1020\n",
      "Epoch 87/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.2808 - loss: 0.1004 - val_accuracy: 0.2727 - val_loss: 0.1028\n",
      "Epoch 88/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.2871 - loss: 0.1005 - val_accuracy: 0.2644 - val_loss: 0.1027\n",
      "Epoch 89/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.2749 - loss: 0.1005 - val_accuracy: 0.2751 - val_loss: 0.1025\n",
      "Epoch 90/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.2816 - loss: 0.1007 - val_accuracy: 0.2823 - val_loss: 0.1022\n",
      "Epoch 91/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.2965 - loss: 0.1005 - val_accuracy: 0.2739 - val_loss: 0.1023\n",
      "Epoch 92/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.2767 - loss: 0.1006 - val_accuracy: 0.2691 - val_loss: 0.1017\n",
      "Epoch 93/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.2997 - loss: 0.0996 - val_accuracy: 0.2799 - val_loss: 0.1029\n",
      "Epoch 94/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.3039 - loss: 0.0991 - val_accuracy: 0.2775 - val_loss: 0.1021\n",
      "Epoch 95/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.2993 - loss: 0.0998 - val_accuracy: 0.2799 - val_loss: 0.1022\n",
      "Epoch 96/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.2886 - loss: 0.1000 - val_accuracy: 0.2667 - val_loss: 0.1023\n",
      "Epoch 97/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.3036 - loss: 0.0995 - val_accuracy: 0.2620 - val_loss: 0.1024\n",
      "Epoch 98/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.2922 - loss: 0.0999 - val_accuracy: 0.2536 - val_loss: 0.1026\n",
      "Epoch 99/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.2933 - loss: 0.0991 - val_accuracy: 0.2739 - val_loss: 0.1024\n",
      "Epoch 100/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.2937 - loss: 0.0992 - val_accuracy: 0.2679 - val_loss: 0.1019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "\n",
    "# 입력 데이터를 3차원으로 변환\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "input_shape = (10, 1)  # 특성 수: 10, 채널: 1\n",
    "output_shape = 28  # 출력 레이블의 수\n",
    "base_model = create_base_cnn_model(input_shape, output_shape)\n",
    "\n",
    "# 모델 학습\n",
    "base_model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n",
    "\n",
    "# 모델 저장\n",
    "base_model.save('base_cnn_model_abalone.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "562784e6-eb18-4b53-849a-0ab4a8b0c226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.0044 - loss: 0.6225 - val_accuracy: 0.0024 - val_loss: 0.3277\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.0327 - loss: 0.2579 - val_accuracy: 0.1519 - val_loss: 0.1520\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.1708 - loss: 0.1439 - val_accuracy: 0.1519 - val_loss: 0.1320\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.1707 - loss: 0.1281 - val_accuracy: 0.1519 - val_loss: 0.1264\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.1676 - loss: 0.1243 - val_accuracy: 0.1519 - val_loss: 0.1234\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.1847 - loss: 0.1214 - val_accuracy: 0.1902 - val_loss: 0.1206\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.2293 - loss: 0.1181 - val_accuracy: 0.2213 - val_loss: 0.1168\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.2206 - loss: 0.1150 - val_accuracy: 0.2392 - val_loss: 0.1126\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.2388 - loss: 0.1100 - val_accuracy: 0.2476 - val_loss: 0.1094\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.2673 - loss: 0.1075 - val_accuracy: 0.2596 - val_loss: 0.1074\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.2449 - loss: 0.1068 - val_accuracy: 0.2739 - val_loss: 0.1061\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.2574 - loss: 0.1049 - val_accuracy: 0.2811 - val_loss: 0.1051\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.2605 - loss: 0.1051 - val_accuracy: 0.2608 - val_loss: 0.1043\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.2716 - loss: 0.1033 - val_accuracy: 0.2727 - val_loss: 0.1038\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.2776 - loss: 0.1026 - val_accuracy: 0.2763 - val_loss: 0.1033\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.2655 - loss: 0.1036 - val_accuracy: 0.2799 - val_loss: 0.1029\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.2786 - loss: 0.1023 - val_accuracy: 0.2751 - val_loss: 0.1028\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.2796 - loss: 0.1013 - val_accuracy: 0.2751 - val_loss: 0.1024\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.2848 - loss: 0.1014 - val_accuracy: 0.2679 - val_loss: 0.1023\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.2701 - loss: 0.1022 - val_accuracy: 0.2763 - val_loss: 0.1022\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.2810 - loss: 0.1017 - val_accuracy: 0.2751 - val_loss: 0.1020\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.2966 - loss: 0.1000 - val_accuracy: 0.2703 - val_loss: 0.1018\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.2806 - loss: 0.1015 - val_accuracy: 0.2787 - val_loss: 0.1018\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.2879 - loss: 0.1020 - val_accuracy: 0.2751 - val_loss: 0.1018\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.2855 - loss: 0.1010 - val_accuracy: 0.2644 - val_loss: 0.1019\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.2905 - loss: 0.1006 - val_accuracy: 0.2715 - val_loss: 0.1017\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.2879 - loss: 0.1007 - val_accuracy: 0.2775 - val_loss: 0.1017\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.2968 - loss: 0.1006 - val_accuracy: 0.2811 - val_loss: 0.1015\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.2866 - loss: 0.1003 - val_accuracy: 0.2739 - val_loss: 0.1015\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.2927 - loss: 0.1007 - val_accuracy: 0.2799 - val_loss: 0.1015\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.2899 - loss: 0.1003 - val_accuracy: 0.2691 - val_loss: 0.1017\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.2984 - loss: 0.0998 - val_accuracy: 0.2727 - val_loss: 0.1015\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.2900 - loss: 0.1002 - val_accuracy: 0.2727 - val_loss: 0.1015\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.2778 - loss: 0.1003 - val_accuracy: 0.2775 - val_loss: 0.1014\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.2929 - loss: 0.1003 - val_accuracy: 0.2775 - val_loss: 0.1015\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.2892 - loss: 0.1004 - val_accuracy: 0.2751 - val_loss: 0.1013\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.2688 - loss: 0.1008 - val_accuracy: 0.2727 - val_loss: 0.1015\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.2872 - loss: 0.1006 - val_accuracy: 0.2739 - val_loss: 0.1014\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.2946 - loss: 0.1004 - val_accuracy: 0.2691 - val_loss: 0.1016\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.2897 - loss: 0.1001 - val_accuracy: 0.2775 - val_loss: 0.1014\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.2887 - loss: 0.0993 - val_accuracy: 0.2739 - val_loss: 0.1014\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.2769 - loss: 0.1012 - val_accuracy: 0.2727 - val_loss: 0.1015\n",
      "Epoch 43/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.2921 - loss: 0.1006 - val_accuracy: 0.2799 - val_loss: 0.1016\n",
      "Epoch 44/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.2880 - loss: 0.1006 - val_accuracy: 0.2751 - val_loss: 0.1017\n",
      "Epoch 45/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.2841 - loss: 0.1012 - val_accuracy: 0.2775 - val_loss: 0.1015\n",
      "Epoch 46/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.2979 - loss: 0.1004 - val_accuracy: 0.2727 - val_loss: 0.1014\n",
      "Epoch 47/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.2995 - loss: 0.1002 - val_accuracy: 0.2787 - val_loss: 0.1013\n",
      "Epoch 48/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.2911 - loss: 0.1015 - val_accuracy: 0.2823 - val_loss: 0.1014\n",
      "Epoch 49/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.2849 - loss: 0.0999 - val_accuracy: 0.2715 - val_loss: 0.1015\n",
      "Epoch 50/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.2823 - loss: 0.0999 - val_accuracy: 0.2739 - val_loss: 0.1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# 기존 모델 불러오기\n",
    "pretrained_model = load_model('base_cnn_model_abalone.h5')\n",
    "\n",
    "# 사전 학습된 모델의 레이어를 고정\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 새로운 레이어 추가\n",
    "model_finetune = Sequential(pretrained_model.layers)\n",
    "model_finetune.add(Dense(32, activation='relu'))\n",
    "model_finetune.add(Dense(output_shape, activation='sigmoid'))  # 최종 출력층 (다중 레이블)\n",
    "\n",
    "# 모델 컴파일\n",
    "model_finetune.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tuning 모델 학습\n",
    "model_finetune.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n",
    "\n",
    "# 새로운 모델 저장\n",
    "model_finetune.save('fine_tuned_cnn_model_abalone.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
